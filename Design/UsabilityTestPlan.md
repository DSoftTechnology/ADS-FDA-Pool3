#Agile Delivery Services (ADS) Food and Drug Administration (FDA) Food Recall Reports 
#Version 1.0
#Usability Test Plan

June 24, 2015


DSoft Technology Company

1155 Kelly Johnson Blvd,

Suite 304

Colorado Springs, CO 80920


##Document Overview
This document defines a test plan for conducting a usability test during the development of Agile Delivery Services (ADS) Food and Drug Administration (FDA) Enforcement Reports web site, Version 1.0. The purpose of this test plan is to establish and validate user performance metrics and to identify potential design issues to improve end-user satisfaction and to improve efficiency and productivity.
The following are the usability test objectives:
*	To identify usability issues associated with user interface and content areas. Potential sources of error may include:
    *	Navigation errors – failure to locate functions, excessive keystrokes to complete a function, failure to follow recommended screen flow.
    *	Presentation errors – failure to locate and properly act upon desired information in screens, selection errors due to labeling ambiguities
    *	Control usage problems – improper toolbar or entry field usage.
*	Exercise the application or web site under controlled test conditions with representative users. Data will be used to access whether usability goals regarding an effective, efficient, and well-received user interface have been achieved.
*	To establish user performance baseline and user satisfaction levels for future usability assessments.
*	To provide user performance measures such as critical errors, non-critical errors, and subjective evaluations.

##Methodology
Usability testing will be conducted inside DSoft Technology office in Colorado Springs, Colorado. Participants will be escorted to DSoft Technology’s conference room where 8 personal computers / laptops are configured with Windows 7, Internet Explorer (IE) v11 and the latest version of Firefox/Chrome. The conference room also has a laptop with Windows 7, IE, v11 installed connected to a projector to display the video output on a large screen. The facilitator will provide an introductory presentation followed by a short review/mission of the ADS Food Recall Reports web site and instruct the participants that they are evaluating the web site, rather than the facilitator evaluating the participant and that the following measures will be collected.
*	Demographic information
*	Satisfaction assessment
*	Improvement suggestions

##Participants
DSoft Technology chose to use Hallway Testing initially as we wanted participants that were unfamiliar with the website and wanted to uncover the most obvious problems. These users, who don’t necessarily have an interest in the web site, will be happy to give their opinion but may miss issues actual users will encounter. Therefore, relying on this one method of testing is not recommended as we would want to have users with specialize skills and target the specific user groups. The design of the reports was made with three user groups in mind (three different reports) however our initial usability testing does not differ in the recruitment method, eligibility characteristics or expected skills and knowledge. All potential participants however will be asked if they use the internet to verify the web browser experience. Candidates with less than 1 year of internet experience will not be consider appropriate participants.

ADS FDA Food Recall Reports web site will be tested by the following user groups:

| User Group            | Recruitment Method                          | Eligibility Characteristics  | Expected Skills/Knowledge | Number of Participants | Session Length | Test Date |
| --------------------- |---------------------------------------------| ---------------------------- | ---- | ---- | ---- | ---- |
| Geographic researcher | Hallway testing – friends/family/co-workers | No prior experience with Food Recalls Reports 4 females, 4 males | Used Internet Explorer or Firefox/Chorme browser for at least 1 year | 8 | 1 hour | 25 June 2015 |
| Business researcher   | Hallway testing – friends/family/co-workers      |  No prior experience with Food Recalls Reports Owns a food-related business. 4 females, 1 males | Used Internet Explorer  or Firefox/Chome browser for at least 1 year | 8 | 1 hour |  25 June 2015 |
| Public Health Researcher   | Hallway testing – friends/family/co-workers      |  No prior experience with Food Recalls Reports Owns a food-related business. 4 females, 4 males | Used Internet Explorer or Firefox/chrome browser for at least 1 year. | 8 | 1 hour | 25 June 2015 |

The participants' responsibilities will be to attempt to complete a set of representative task scenarios presented to them in as efficient and timely a manner as possible, and to provide feedback regarding the usability and acceptability of the user interface.  The participants will be directed to provide honest opinions regarding the usability of the application, and to participate in post-session subjective questionnaires and debriefing.

##Training
The facilitator will provide an introductory presentation followed by a short review/mission of the ADS Food Allergy Reports web site and instruct the participants that they are evaluating the web site, rather than the facilitator evaluating the participant.    A review of the equipment and the software installed on the desktops / laptops will be provided.  The review will include the following pages based on the user group.

| User Group            | Recruitment Method                          |
| --------------------- |---------------------------------------------|
| Geographic researcher | Landing page (5 minutes) Recall Locations (5 minutes) Recall Frequency (5 minutes) |
| Business researcher | Landing page (5 minutes) Recall Frequency (5 minutes) Enforcement Report List (5 minutes) |
| Public Health Researcher | Landing page (5 minutes) Public and Company Cost (5 minutes) Recall Locations (5 minutes) Recall Frequency (5 minutes) |

##Procedures

Participants will be provided with a personal computer / laptop to conduct their usability tests.  The personal computers /laptops are configured with Windows 7, Internet Explorer v10 and the latest version of Firefox/Chrome.   Participants will be able to select their browser of choice either Internet Explorer v10 or the latest version of Chrome/, Firefox) to conduct the tests. 

The participant’s interactions with the web site will be monitored by the facilitator and note taker(s) seated in the conference room will capture feedback and comments.  Each test session will be videotaped.  The facilitator will conduct a brief review explaining that the amount of time taken to complete the test task will be measured and the site exploration should not occur until after the task completed. 

The facilitator will distribute a consent that acknowledges the participation as voluntary and that the session will be videotaped with participant’s identification safeguarded. After collecting participants’ signed consent, the facilitator will ask the participants if they have any questions.

After a brief questions/answer session, participants will complete a demographic and background information questionnaire.  Each test task will start with a participant reading a test task description out loud from the printed copy followed by the test implementation. Time measurement begins when the participant starts the task.  

The facilitator will instruct the participant to ‘think aloud’ so that a verbal record exists of their interaction with the web site. During the test, the facilitator and note taker(s) will observe participant’s behavior and manually record it using pencil and paper. 

The facilitator will instruct the participant to ‘think aloud’ so that a verbal record exists of their interaction with the Web site/Web application. The facilitator will observe and enter user behavior, user comments, and system actions in the data logging application.

After each task, the participant will complete the post-task questionnaire and elaborate on the task session.  In addition, participants will have a chance to conduct their own independent usability tests using their browser of choice. The post-task questionnaire will address usability of each web page in the test implementation and suggested improvements or changes to each web page.  Results of participant’s independent usability tests will be include in the post-task questionnaire. After the participant completes all tasks, he/she will complete the satisfaction questionnaire. 

##Roles

The following roles will be included in ADS Food Recall Reports web site usability testing.  An individual may possess multiple roles. Usability tasks may not require all roles. 

###Trainer
*	Provide training overview prior to usability testing.

###Facilitator
*	Givers a brief overview of the web site.
*	Defines usability and purpose of usability testing to participants
*	Gives a brief overview of the usability test procedures to participants
*	Assists in conduct of participant and observer debriefing sessions
*	Assists participant during the tests as needed

###Note Taker/Data Logger
*	Silent observer
*	Records participant's actions and comments
*	Assists in identifying procedural errors and participant’s behavior

###Test Participants
*	Attends test session on time
*	Completes demographic questionnaire
*	Completes assigned test tasks
*	Completes post-task questionnaire
*	Completes satisfaction questionnaire

###Ethics
Participant’s identity should be safeguarded and not be used anywhere outside the testing session. All measures should be taken to discard any personal information collected after data is analyzed.

##Usability Tasks

The test tasks below are required to be reviewed by the development team consisting of the business analyst, developers, and testers.  A development review will ensure that the format and the content is suitable for the total web site evaluation.  Usability test tasks acceptance will be documented prior to conducting usability test.

###Tasks for Geographic Researcher
####Task 1 – 5 minutes:
Task Description: Use dsoft-ads-staging.azurewebsites.net web site to locate all peanut butter products recalls in the state of Colorado. You must complete this task in 5 minutes.  

Objectives:  
*	User finds Recall Locations report in one click.  
* Users uses the state and keyword filters to retrieve specific data.
*	User understands the meaning of the data being represented on the graph.

####Task 2 – 5 minutes:
Task Description: Use dsoft-ads-staging.azurewebsites.net web site to locate all milk products recalls in the state of Colorado during the last year.  You must complete this task in 5 minutes.

Objectives: 

*	User finds Recall Locations report in one click. 
*	User uses the state, keyword and date range filters to retrieve specific data.
*	User understands the meaning of the data being represented on the graph.

###Task Scenarios for Business Researcher
####Task 1 – 5 minutes:
Task Description: Use dsoft-ads-staging.azurewebsites.net web site to see how frequently peanut butter products are recalled in the state of Colorado. You must complete this task in 5 minutes.

Objectives:

*	User finds Recall Frequency report in one click.
*	User uses the keyword and state filters to retrieve the specific data.
*	User understands the meaning of the data being represented on the graph.

####Task 2 – 5 minutes:
Task Description: Use dsoft-ads-staging.azurewebsites.net web site to see why peanut butter products were recalled in the state of Colorado in the course of last year. You must complete this task in 5 minutes.

Objectives:

*	User finds Enforcement Report List report in one click.
*	User uses the state, keyword and date range filters to retrieve specific data.
*	User understands the meaning of the data being represented on the graph.

###Task Scenarios for Public Health Researcher
####Task 1 – 5 minutes: 
Task Description: Use dsoft-ads-staging.azurewebsites.net web site to see top 10 companies with most recalls.  You must complete this task in 5 minutes.

Objectives:

*	User finds Report List report in one click.
*	User understands the meaning of the data being represented on the graph (user recognizes that decreasing size of circles over the 10 year span means that the company is improving and increasing size of circles over the 10 year span means the company is not improving).

####Task 2 – 5 minutes:
Task Description: Use dsoft-ads-staging.azurewebsites.net web site to see top 10 companies for the state of Colorado with the most recalls.  You must complete this task in 5 minutes.

Objectives:

•	User finds Report List report in one click.
•	User uses the state filter to retrieve the specific data.
•	User understands the meaning of the data being represented on the graph (user recognizes that decreasing size of circles over the 10 year span means that the company is improving and increasing size of circles over the 10 year span means the company is not improving).


##Usability Metrics
Usability metrics refer to user performance measured to satisfy usability requirements. The following usability metrics will be used to measure user performance.
###Scenario Completion
Each test task will require participant to complete a particular scenario within a designated time period.  The scenario is completed when the participant indicates the scenario's goal has been obtained (whether successfully or unsuccessfully) or the participant requests and receives sufficient guidance as to warrant scoring the scenario as a critical error.
###Critical Errors
Critical errors are deviations at completion from the targets of the scenario.  Obtaining or otherwise reporting of the wrong data value due to participant workflow is a critical error. Participants may or may not be aware that the task goal is incorrect or incomplete.

Independent completion of the scenario is a universal goal; help obtained from the other usability test roles is cause to score the scenario a critical error.  Critical errors can also be assigned when the participant initiates (or attempts to initiate) and action that will result in the goal state becoming unobtainable.  In general, critical errors are unresolved errors during the process of completing the task or errors that produce an incorrect outcome.

####Non-critical Errors
Non-critical errors are errors that are recovered from by the participant or, if not detected, do not result in processing problems or unexpected results.  Although non-critical errors can be undetected by the participant, when they are detected they are generally frustrating to the participant.

These errors may be procedural, in which the participant does not complete a scenario in the most optimal means (e.g., excessive steps and keystrokes).  These errors may also be errors of confusion (ex., initially selecting the wrong function, using a user-interface control incorrectly such as attempting to edit an un-editable field).
Noncritical errors can always be recovered from during the process of completing the scenario.  Exploratory behavior, such as opening the wrong menu while searching for a function will be coded as a non-critical error.

####Error-Free Rate:
Error-free rate is the percentage of test participants who complete the task without any errors (critical or non-critical errors).

####Subjective Evaluations
Subjective evaluations regarding ease of use and satisfaction will be collected via questionnaires, and during debriefing at the conclusion of the session.  The questionnaires will utilize free-form responses and rating scales.

####Scenario Completion Time
Scenario completion time refers to the time to complete each scenario, which does not include subjective evaluation such as questionnaire. 

####Likes, Dislikes and Recommendations
Participants provide what they liked most about the site, what they liked least about the site, and recommendations for improving the site.

##Usability Goals

The following usability goals are set for ADS Food Recalls Reports web site.

###Completion Rate
Completion rate refers to the percentage of the test participants who successfully complete the task without critical errors.   A completion rate goal is 70% along with a 95% confidence that the average time to complete a task is between 2.73 and 3.71 minutes for each task.

###Error-free rate
Error-free rate is the percentage of test participants who complete the task without any errors (critical or non-critical errors).  A non-critical error is an error that would not have an impact on the final output of the task but would result in the task being completed less efficiently.

###Time on Task (TOT)
Time on task refers to the time taken by the participant to complete the task from the time the participants starts the task to the time he indicates completion.  Time on task should be reached for each task as designated above.

###Subjective Measures
Subjective opinions about specific tasks, time to perform each task, features, and functionality will be surveyed.  At the end of the test, participants will rate their satisfaction with the overall system.  Combined with the interview/debriefing session, these data are used to assess attitudes of the participants.

###Problem Severity 
To prioritize recommendations, a method of problem severity classification will be used in the analysis of the data collected during evaluation activities.  The approach treats problem severity as a combination of two factors - the impact of the problem and the frequency of users experiencing the problem during the evaluation.

####Impact
Impact is the ranking of the consequences of the problem by defining the level of impact that the problem has on successful task completion.  There are three levels of impact:
*	High - prevents the user from completing the task (critical error)
*	Moderate - causes user difficulty but the task can be completed (non-critical error)
*	Low - minor problems that do not significantly affect the task completion (non-critical error)

####Frequency
Frequency is the percentage of participants who experience the problem when working on a task.
*	High: 25% or more of the participants experience the problem
*	Moderate: 12.5% - 25% of participants experience the problem
*	Low: 12.5% or fewer of the participants experience the problem

####Problem Severity Classification
The identified severity for each problem implies a general reward for resolving it, and a general risk for not addressing it, in the current release.


  <b>Severity 1</b> - High impact problems that often prevent a user from correctly completing a task.  They occur in       varying frequency and are characteristic of calls to the Help Desk.  Reward for resolution is typically exhibited in      fewer Help Desk calls and reduced redevelopment costs.

  <b>Severity 2</b> - Moderate to high frequency problems with moderate to low impact are typical of erroneous actions      that the participant recognizes needs to be undone.  Reward for resolution is typically exhibited in reduced time on      task and decreased training costs.

  <b>Severity 3</b> - Either moderate problems with low frequency or low problems with moderate frequency; these are        minor annoyance problems faced by a number of participants.  Reward for resolution is typically exhibited in reduced      time on task and increased data integrity.

  <b>Severity 4</b> - Low impact problems faced by few participants; there is low risk to not resolving these problems.      Reward for resolution is typically exhibited in increased user satisfaction.


###Reporting Test Results
The usability test report will be provided after all participants complete testing on 26 June 2015. The test results will be provided in the hard-copy format. The report will contain usability metrics defined in this document compared to the usability goals defined in this document. Completion Rate during testing will be compared to the completion rate goal of 70%.  Also, the TOT during testing will be compared to set time for each task.

In addition, the report will identify usability problems and recommended solutions.  Each recommended solution will be evaluated by development team during the usability testing review meeting to establish an implementation plan with estimated completion time. 




